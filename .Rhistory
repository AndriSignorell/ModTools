head(model.frame(r.rf))
head(model.frame(r.svm))
head(model.frame(r.c5))
head(model.frame(r.nn))
head(model.frame(r.lda))
head(model.frame(r.nb))
head(model.frame(r.qda))
head(model.frame(r.lb))
head(model.frame(r.glm))
r.c5$levels
r.rf$classes
r.glm$
Response(r.c5)
Response(r.c5)
lapply(mods, function(x) str(Response(x)))
lapply(mods, function(x) levels(Response(x)))
library(ModTools)
mdiab <- formula(diabetes ~ pregnant + glucose + pressure + triceps
+ insulin + mass + pedigree + age)
r.glm <- FitMod(mdiab, data=d.pim$train, fitfn="logit")
sapply(mods, BrierScore)
d.pim <- SplitTrainTest(d.pima, p = 0.2)
mdiab <- formula(diabetes ~ pregnant + glucose + pressure + triceps
+ insulin + mass + pedigree + age)
r.glm <- FitMod(mdiab, data=d.pim$train, fitfn="logit")
r.rp <- FitMod(mdiab, data=d.pim$train, fitfn="rpart")
r.rf <- FitMod(mdiab, data=d.pim$train, fitfn="randomForest")
r.svm <- FitMod(mdiab, data=d.pim$train, fitfn="svm")
r.c5 <- FitMod(mdiab, data=d.pim$train, fitfn="C5.0")
r.nn <- FitMod(mdiab, data=d.pim$train, fitfn="nnet")
r.nb <- FitMod(mdiab, data=d.pim$train, fitfn="naive_bayes")
r.lda <- FitMod(mdiab, data=d.pim$train, fitfn="lda")
r.qda <- FitMod(mdiab, data=d.pim$train, fitfn="qda")
r.lb <- FitMod(mdiab, data=d.pim$train, fitfn="lb")
mods <- list(glm=r.glm, rp=r.rp, rf=r.rf, svm=r.svm, c5=r.c5
, nn=r.nn, nb=r.nb, lda=r.lda, qda=r.qda, lb=r.lb)
sapply(mods, BrierScore)
Response(r.svm)
head(Response(r.svm))
head(Response(r.glm))
head(predict(r.svm))
head(predict(r.svm, type="prob"))
head(predict(r.glm, type="prob")
)
predict.svm
e1071:::predict.svm
pred <- predict(model, x, decision.values = TRUE, probability = TRUE)
attr(pred, "decision.values")[1:4,]
pred <- predict(model, x, decision.values = TRUE, probability = TRUE)
attr(pred, "decision.values")[1:4,]
pred <- predict(r.svm, x, decision.values = TRUE, probability = TRUE)
pred <- predict(r.svm, decision.values = TRUE, probability = TRUE)
attr(pred, "decision.values")[1:4,]
attr(pred, "probabilities")[1:4,]
sapply(mods, function(x) head(predict(x)))
sapply(mods, function(x) head(predict(x, type="prob")))
lapply(mods, function(x) head(predict(x, type="prob")))
DescToolsAddIns:::Select()
DescToolsAddIns:::BuildModel()
FitMod(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data=iris,
fitfn = "svm")
miris <- formula(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data=iris)
miris
r.glm <- FitMod(mdiab, fitfn="logit")
r.glm <- FitMod(miris, fitfn="logit")
r.glm <- FitMod(miris, data=iris, fitfn="logit")
r.rp <- FitMod(miris, data=iris,fitfn="rpart")
r.rf <- FitMod(miris, data=iris,fitfn="randomForest")
r.svm <- FitMod(miris, data=iris,fitfn="svm")
r.c5 <- FitMod(miris, data=iris,fitfn="C5.0")
r.nn <- FitMod(miris, data=iris,fitfn="nnet")
r.nb <- FitMod(miris, data=iris,fitfn="naive_bayes")
r.lda <- FitMod(miris, data=iris,fitfn="lda")
r.qda <- FitMod(miris, data=iris,fitfn="qda")
r.lb <- FitMod(miris, data=iris,fitfn="lb")
mods <- list(glm=r.glm, rp=r.rp, rf=r.rf, svm=r.svm, c5=r.c5
, nn=r.nn, nb=r.nb, lda=r.lda, qda=r.qda, lb=r.lb)
lapply(mods, function(x) head(predict(x, type="prob")))
predict(r.rp)
head(predict(r.rp, type="prob")
)
r.rp <- FitMod(miris, data=iris,fitfn="rpart")
r.rf <- FitMod(miris, data=iris,fitfn="randomForest")
r.svm <- FitMod(miris, data=iris,fitfn="svm")
r.c5 <- FitMod(miris, data=iris,fitfn="C5.0")
r.nn <- FitMod(miris, data=iris,fitfn="nnet")
r.nb <- FitMod(miris, data=iris,fitfn="naive_bayes")
r.lda <- FitMod(miris, data=iris,fitfn="lda")
r.qda <- FitMod(miris, data=iris,fitfn="qda")
r.lb <- FitMod(miris, data=iris,fitfn="lb")
mods <- list(rp=r.rp, rf=r.rf, svm=r.svm, c5=r.c5
, nn=r.nn, nb=r.nb, lda=r.lda, qda=r.qda, lb=r.lb)
lapply(mods, function(x) head(predict(x, type="prob")))
e1071:::predict.svm
class(r.svm)
predict
predict(r.svm, type="prob")
predict
predict.FitMod <- function(object, ...){
res <- UseMethod("predict")
if(inherits(object), "svm"){
predict.FitMod <- function(object, ...){
res <- UseMethod("predict")
if(inherits(object, "svm")){
if(ncol(res)==2){
return(res[, c(2,1)])
}
} else {
return(res)
}
}
predict(r.svm, type="prob")
predict(r.rp, type="prob")
predict.FitMod <- function(object, ...){
res <- predict(object, ...)
if(inherits(object, "svm")){
if(ncol(res)==2){
return(res[, c(2,1)])
}
} else {
return(res)
}
}
predict(r.rp, type="prob")
predict.FitMod <- function(object, ...){
res <- predict(object, ...)
if(inherits(object, "svm")){
if(ncol(res)==2){
return(res[, c(2,1)])
}
} else {
return(res)
}
}
predict(r.rp, type="prob")
predict.FitMod <- function(object, ...){
class(object) <- class(object)[class(object) != "FitMod"]
res <- predict(object, ...)
if(inherits(object, "svm")){
if(ncol(res)==2){
return(res[, c(2,1)])
}
} else {
return(res)
}
}
predict(r.rp, type="prob")
predict(r.svm, type="prob")
debug(predict.FitMod)
predict(r.svm, type="prob")
head(res)
predict(r.svm, type="prob")
class(r.svm)
class(r.svm)[1] <- NULL
class(r.svm)[1] <- NA
class(r.svm)
predict(r.svm, type="prob")
r.svm <- FitMod(miris, data=iris,fitfn="svm")
head(predict(r.svm, type="prob"))
undebug(predict.FitMod)
class(r.svm) <- class(r.svm)[2:3]
head(predict(r.svm, type="prob")
)
debug(predict)
r.svm <- FitMod(miris, data=iris,fitfn="svm")
predict(r.svm, type="prob")
predict.FitMod <- NULL
predict(r.svm, type="prob")
r.svm$nclasses
library(ModTools)
d.pim <- SplitTrainTest(d.pima, p = 0.2)
mdiab <- formula(diabetes ~ pregnant + glucose + pressure + triceps
+ insulin + mass + pedigree + age)
r.glm <- FitMod(mdiab, data=d.pim$train, fitfn="logit")
r.rp <- FitMod(mdiab, data=d.pim$train, fitfn="rpart")
r.rf <- FitMod(mdiab, data=d.pim$train, fitfn="randomForest")
r.svm <- FitMod(mdiab, data=d.pim$train, fitfn="svm")
r.c5 <- FitMod(mdiab, data=d.pim$train, fitfn="C5.0")
r.nn <- FitMod(mdiab, data=d.pim$train, fitfn="nnet")
r.nb <- FitMod(mdiab, data=d.pim$train, fitfn="naive_bayes")
r.lda <- FitMod(mdiab, data=d.pim$train, fitfn="lda")
r.qda <- FitMod(mdiab, data=d.pim$train, fitfn="qda")
r.lb <- FitMod(mdiab, data=d.pim$train, fitfn="lb")
mods <- list(glm=r.glm, rp=r.rp, rf=r.rf, svm=r.svm, c5=r.c5
, nn=r.nn, nb=r.nb, lda=r.lda, qda=r.qda, lb=r.lb)
lapply(mods, function(x) head(predict(x, type="prob")))
predict(r.svm, type="prob")
head(predict(r.svm, type="prob"))
head(predict(r.rp, type="prob")
)
library(ModTools)
head(predict(r.svm, type="prob"))
head(predict(r.rp, type="prob")
)
head(predict(r.svm, type="prob")
)
debug(.predict.svm)
predict(r.svm, type="prob")
debug(ModTools:::.predict.svm)
predict(r.svm, type="prob")
object$nclasses
head(res)
res[, c(2,1)]
head(res)
head(predict(r.svm, type="prob"))
predict(r.svm, type="prob")
head(predict(r.svm, type="prob"))
library(ModTools)
head(predict(r.svm, type="prob"))
predict(r.rp, type="prob")
head(predict(r.rp, type="prob")
)
head(predict(r.svm, type="prob"))
mods <- list(rp=r.rp, rf=r.rf, svm=r.svm, c5=r.c5
, nn=r.nn, nb=r.nb, lda=r.lda, qda=r.qda, lb=r.lb)
lapply(mods, function(x) head(predict(x, type="prob")))
library(ModTools)
d.pim <- SplitTrainTest(d.pima, p = 0.2)
mdiab <- formula(diabetes ~ pregnant + glucose + pressure + triceps
+ insulin + mass + pedigree + age)
r.glm <- FitMod(mdiab, data=d.pim$train, fitfn="logit")
r.rp <- FitMod(mdiab, data=d.pim$train, fitfn="rpart")
r.rf <- FitMod(mdiab, data=d.pim$train, fitfn="randomForest")
r.svm <- FitMod(mdiab, data=d.pim$train, fitfn="svm")
r.c5 <- FitMod(mdiab, data=d.pim$train, fitfn="C5.0")
r.nn <- FitMod(mdiab, data=d.pim$train, fitfn="nnet")
r.nb <- FitMod(mdiab, data=d.pim$train, fitfn="naive_bayes")
r.lda <- FitMod(mdiab, data=d.pim$train, fitfn="lda")
r.qda <- FitMod(mdiab, data=d.pim$train, fitfn="qda")
r.lb <- FitMod(mdiab, data=d.pim$train, fitfn="lb")
mods <- list(glm=r.glm, rp=r.rp, rf=r.rf, svm=r.svm, c5=r.c5
, nn=r.nn, nb=r.nb, lda=r.lda, qda=r.qda, lb=r.lb)
sapply(mods, BrierScore)
head(predict(r.svm, type="prob"))
predict(r.rp, type="prob")
head(predict(r.svm, type="prob"))
head(predict(r.rp, type="prob"))
lapply(mods, function(x) head(predict(x, type="prob")))
library(ModTools)
lapply(mods, function(x) head(predict(x, type="prob")))
mods <- list(rp=r.rp, rf=r.rf, svm=r.svm, c5=r.c5
, nn=r.nn, nb=r.nb, lda=r.lda, qda=r.qda, lb=r.lb)
lapply(mods, function(x) head(predict(x, type="prob")))
sapply(mods, BrierScore)
library(ModTools)
d.pim <- SplitTrainTest(d.pima, p = 0.2)
mdiab <- formula(diabetes ~ pregnant + glucose + pressure + triceps
+ insulin + mass + pedigree + age)
r.glm <- FitMod(mdiab, data=d.pim$train, fitfn="logit")
r.rp <- FitMod(mdiab, data=d.pim$train, fitfn="rpart")
r.rf <- FitMod(mdiab, data=d.pim$train, fitfn="randomForest")
r.svm <- FitMod(mdiab, data=d.pim$train, fitfn="svm")
r.c5 <- FitMod(mdiab, data=d.pim$train, fitfn="C5.0")
r.nn <- FitMod(mdiab, data=d.pim$train, fitfn="nnet")
r.nb <- FitMod(mdiab, data=d.pim$train, fitfn="naive_bayes")
r.lda <- FitMod(mdiab, data=d.pim$train, fitfn="lda")
r.qda <- FitMod(mdiab, data=d.pim$train, fitfn="qda")
r.lb <- FitMod(mdiab, data=d.pim$train, fitfn="lb")
mods <- list(glm=r.glm, rp=r.rp, rf=r.rf, svm=r.svm, c5=r.c5
, nn=r.nn, nb=r.nb, lda=r.lda, qda=r.qda, lb=r.lb)
sapply(mods, BrierScore)
TModC(mods[c(1,2,3)])
TModC(mods)
debug(.predict.svm)
predict(r.svm, type="prob")
debug(ModTools:::.predict.svm)
predict(r.svm, type="prob")
attr(res)
str(res)
str(res)
str(res)
undebug(ModTools:::.predict.svm)
r.svm <- FitMod(mdiab, data=d.pim$train, fitfn="svm")
summary(r.svm)
tu <- Tune(r.svm,
kernel=c("radial", "sigmoid"),
cost=c(0.1,1,10,100,1000),
gamma=c(0.5,1,2,3,4), testset=d.pim$test)
Tune
ModTools:::Tune
ModTools:::Tune.default
tu <- Tune(r.svm,
kernel=c("radial", "sigmoid"),
cost=c(0.1,1,10,100,1000),
gamma=c(0.5,1,2,3,4), testset=d.pim$test)
library(ModTools)
r.svm
tu <- Tune(r.svm,
kernel=c("radial", "sigmoid"),
cost=c(0.1,1,10,100,1000),
gamma=c(0.5,1,2,3,4), testset=d.pim$test)
library(ModTools)
tu <- Tune(r.svm,
kernel=c("radial", "sigmoid"),
cost=c(0.1,1,10,100,1000),
gamma=c(0.5,1,2,3,4), testset=d.pim$test)
predict(r.svm, type="prob")
head(predict(r.svm, type="prob"))
head(predict(r.svm, type="class"))
library(ModTools)
head(predict(r.svm, type="prob"))
head(predict(r.svm, type="class"))
tu <- Tune(r.svm,
kernel=c("radial", "sigmoid"),
cost=c(0.1,1,10,100,1000),
gamma=c(0.5,1,2,3,4), testset=d.pim$test)
head(model.frame(r.glm))
r.glm <- FitMod(diabetes ~ ., data=d.pima, fitfn = "logit")
r.rp <- FitMod(diabetes ~ ., data=d.pima, fitfn = "rpart")
r.rf <- FitMod(diabetes ~ ., data=d.pima, fitfn = "randomForest")
example(TModC)
BrierScore(r.rp)
undebug(BrierScore)
class(r.rp)
methods(BrierScore)
predict(r.glm, type="response")
predict(r.rp, type="prob")
predict(r.rp, type="response")
undebug(predict)
predict.glm
rpart:::predict.rpart
ModelMetrics::brier(r.rp)
ModelMetrics::brier(r.glm)
BrierScore(r.rp)
BrierScore(r.rp)
BrierScore(r.glm)
ModelMetrics::brier(r.rp)
ModelMetrics::brier(r.glm)
BrierScore(r.glm)
BrierScore(r.rp)
BrierScore(r.rf)
ModelMetrics::brier(r.glm)
ModelMetrics::brier(r.rf)
BrierScore(r.glm)
BrierScore(r.rf)
DescToolsAddIns:::BuildModel()
library(ModTools)
DescToolsAddIns:::BuildModel()
r.logit <- FitMod(diabetes ~ ., data=d.pima, fitfn="logit")
summary(r.logit)
BrierScore(r.logit)
library(ModTools)
library(ModTools)
# get binomial model
r.logit <- FitMod(diabetes ~ ., data=d.pima, fitfn="logit")
# calculate Brier score with confidence intervals
BrierScore(r.logit)
BrierScoreCI(r.logit)
BrierScoreCI(r.logit, R=99)
library(ModTools)
# calculate Brier score with confidence intervals
BrierScore(r.logit)
BrierScoreCI(r.logit, R=99)
BrierScoreCI(r.logit, R=99)
warnings()
library(ModTools)
# calculate Brier score with confidence intervals
BrierScore(r.logit)
BrierScoreCI(r.logit, R=99)
library(ModTools)
library(pkgdown)
DescToolsAddIns:::FlipBackSlash()
build_home(pkg="C:/Users/andri/Documents/R/Projects/ModTools")
build_home(pkg="C:/Users/andri/Documents/R/Projects/ModTools")
build_site(pkg="C:/Users/andri/Documents/R/Projects/ModTools")
build_site(pkg="C:/Users/andri/Documents/R/Projects/ModTools")
install.packages("ModTools")
library(ModTools)
url <- "http://www.omegahat.net/R/bin/windows/contrib/4.2/RDCOMClient_0.96-1.zip"
install.packages(url, repos=NULL, type="binary")
library(ModTools)
d.pim <- SplitTrainTest(d.pima, p = 0.2)
mdiab <- formula(diabetes ~ pregnant + glucose + pressure + triceps
+                             + insulin + mass + pedigree + age)
r.glm <- FitMod(mdiab, data=d.pim$train, fitfn="logit")
r.rp <- FitMod(mdiab, data=d.pim$train, fitfn="rpart")
r.rf <- FitMod(mdiab, data=d.pim$train, fitfn="randomForest")
r.svm <- FitMod(mdiab, data=d.pim$train, fitfn="svm")
r.c5 <- FitMod(mdiab, data=d.pim$train, fitfn="C5.0")
r.nn <- FitMod(mdiab, data=d.pim$train, fitfn="nnet")
r.nb <- FitMod(mdiab, data=d.pim$train, fitfn="naive_bayes")
r.lda <- FitMod(mdiab, data=d.pim$train, fitfn="lda")
r.qda <- FitMod(mdiab, data=d.pim$train, fitfn="qda")
r.lb <- FitMod(mdiab, data=d.pim$train, fitfn="lb")
mods <- list(glm=r.glm, rp=r.rp, rf=r.rf, svm=r.svm, c5=r.c5
, nn=r.nn, nb=r.nb, lda=r.lda, qda=r.qda, lb=r.lb)
# insight in the Regression tree
plot(r.rp, box.palette = as.list(Pal("Helsana", alpha = 0.5)))
# Insample accuracy ...
TModC(mods, ord="auc")
# Insample accuracy ...
TModC(mods[1:5], ord="auc")
# Insample accuracy ...
TModC(mods[1:3], ord="auc")
# Insample accuracy ...
TModC(mods[1:2], ord="auc")
# Insample accuracy ...
TModC(mods[1:3], ord="auc")
# Insample accuracy ...
TModC(mods[3], ord="auc")
# Insample accuracy ...
TModC(mods[1], ord="auc")
# Insample accuracy ...
TModC(mods[2], ord="auc")
# Insample accuracy ...
TModC(mods[3], ord="auc")
# Insample accuracy ...
TModC(mods[-3], ord="auc")
# Insample accuracy ...
TModC(mods[c(1,2,4,5)], ord="auc")
# Insample accuracy ...
TModC(mods[c(1,2,4)], ord="auc")
# Insample accuracy ...
TModC(mods[c(1,2,5)], ord="auc")
# Insample accuracy ...
TModC(mods[c(1,2)], ord="auc")
# Insample accuracy ...
TModC(mods[c(1,2,6)], ord="auc")
# Insample accuracy ...
TModC(mods[c(1,2,7)], ord="auc")
# Insample accuracy ...
TModC(mods[c(2)], ord="auc")
# Insample accuracy ...
TModC(mods[c(3)], ord="auc")
debug(TModC)
# Insample accuracy ...
TModC(mods[c(3)], ord="auc")
undebug(TModC)
BrierScore(r.rf)
BrierScore
debug(BrierScore)
BrierScore(r.rf)
r.rf
summary(r.rf)
DescTools::Desc(r.rf)
BrierScore
r.rf
model.extract(r.rf, "response")
head(r.glm$model)
data_name = getCall(r.rf)$data
eval(data_name)
head(eval(data_name)
)
BrierScore
head(eval(data_name))
DescTools::Str(r.rf, max.level=1)
model.response(model.frame(r.rf))
model.frame(r.rf)
model.response(model.frame(r.rf))
BrierScore
r.rp$model
model.extract(r.rp$model, "response")
as.numeric(model.extract(r.rp$model, "response")) - 1
model.response(model.frame(r.rp))
as.numeric(model.response(model.frame(r.rp)) - 1
as.numeric(model.response(model.frame(r.rp))) - 1
as.numeric(model.extract(r.rp$model, "response")) - 1
as.numeric(model.response(model.frame(r.rp))) - 1
as.numeric(model.response(model.frame(r.glm))) - 1
as.numeric(model.response(model.frame(r.rp))) - 1
as.numeric(model.response(model.frame(r.rf))) - 1
as.numeric(model.response(model.frame(r.svm))) - 1
as.numeric(model.response(model.frame(r.c5))) - 1
model.frame(r.c5)
r.c5
as.numeric(model.response(model.frame(r.nn))) - 1
r.naive_bayes
r.nb
as.numeric(model.response(model.frame(r.nb))) - 1
as.numeric(model.response(model.frame(r.lda))) - 1
as.numeric(model.response(model.frame(r.qda))) - 1
as.numeric(model.response(model.frame(r.lb))) - 1
as.numeric(model.extract(r.c5$model, "response")) - 1
r.c5$model
data_name = getCall(r.c5)$data
eval(data_name)
model.extract(r.c5$model, "response")
ModTools::Response
model.response(model.frame(eval(x$call$formula)$terms))
model.response(model.frame(eval(r.rf$call$formula)$terms))
r.rf$call$formula
eval(r.rf$call$formula)
eval(r.rf$call$formula)$terms
x <- r.rf
x$terms <- eval(x$call$formula)
x$terms
model.response(model.frame(x))
resp <- function(x){
x$terms <- eval(x$call$formula)
model.response(model.frame(x))
}
resp(r.rp)
resp(r.glm)
resp(r.rf)
resp(r.svm)
resp(r.nn)
resp(r.lda)
resp(r.qda)
resp(r.c5)
resp(r.lb)
resp(r.c5)
resp(r.nb)
BrierScore
NumResponse <- function(x){
x$terms <- eval(x$call$formula)
as.numeric(model.response(model.frame(x))) - 1
}
NumResponse(r.glm)
NumResponse <- function(x){
x$terms <- eval(x$call$formula)
as.numeric(model.response(model.frame(x))) - 1
}
