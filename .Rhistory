predict(r.svm, type="prob")
predict(r.rp, type="prob")
predict.FitMod <- function(object, ...){
res <- predict(object, ...)
if(inherits(object, "svm")){
if(ncol(res)==2){
return(res[, c(2,1)])
}
} else {
return(res)
}
}
predict(r.rp, type="prob")
predict.FitMod <- function(object, ...){
res <- predict(object, ...)
if(inherits(object, "svm")){
if(ncol(res)==2){
return(res[, c(2,1)])
}
} else {
return(res)
}
}
predict(r.rp, type="prob")
predict.FitMod <- function(object, ...){
class(object) <- class(object)[class(object) != "FitMod"]
res <- predict(object, ...)
if(inherits(object, "svm")){
if(ncol(res)==2){
return(res[, c(2,1)])
}
} else {
return(res)
}
}
predict(r.rp, type="prob")
predict(r.svm, type="prob")
debug(predict.FitMod)
predict(r.svm, type="prob")
head(res)
predict(r.svm, type="prob")
class(r.svm)
class(r.svm)[1] <- NULL
class(r.svm)[1] <- NA
class(r.svm)
predict(r.svm, type="prob")
r.svm <- FitMod(miris, data=iris,fitfn="svm")
head(predict(r.svm, type="prob"))
undebug(predict.FitMod)
class(r.svm) <- class(r.svm)[2:3]
head(predict(r.svm, type="prob")
)
debug(predict)
r.svm <- FitMod(miris, data=iris,fitfn="svm")
predict(r.svm, type="prob")
predict.FitMod <- NULL
predict(r.svm, type="prob")
r.svm$nclasses
library(ModTools)
d.pim <- SplitTrainTest(d.pima, p = 0.2)
mdiab <- formula(diabetes ~ pregnant + glucose + pressure + triceps
+ insulin + mass + pedigree + age)
r.glm <- FitMod(mdiab, data=d.pim$train, fitfn="logit")
r.rp <- FitMod(mdiab, data=d.pim$train, fitfn="rpart")
r.rf <- FitMod(mdiab, data=d.pim$train, fitfn="randomForest")
r.svm <- FitMod(mdiab, data=d.pim$train, fitfn="svm")
r.c5 <- FitMod(mdiab, data=d.pim$train, fitfn="C5.0")
r.nn <- FitMod(mdiab, data=d.pim$train, fitfn="nnet")
r.nb <- FitMod(mdiab, data=d.pim$train, fitfn="naive_bayes")
r.lda <- FitMod(mdiab, data=d.pim$train, fitfn="lda")
r.qda <- FitMod(mdiab, data=d.pim$train, fitfn="qda")
r.lb <- FitMod(mdiab, data=d.pim$train, fitfn="lb")
mods <- list(glm=r.glm, rp=r.rp, rf=r.rf, svm=r.svm, c5=r.c5
, nn=r.nn, nb=r.nb, lda=r.lda, qda=r.qda, lb=r.lb)
lapply(mods, function(x) head(predict(x, type="prob")))
predict(r.svm, type="prob")
head(predict(r.svm, type="prob"))
head(predict(r.rp, type="prob")
)
library(ModTools)
head(predict(r.svm, type="prob"))
head(predict(r.rp, type="prob")
)
head(predict(r.svm, type="prob")
)
debug(.predict.svm)
predict(r.svm, type="prob")
debug(ModTools:::.predict.svm)
predict(r.svm, type="prob")
object$nclasses
head(res)
res[, c(2,1)]
head(res)
head(predict(r.svm, type="prob"))
predict(r.svm, type="prob")
head(predict(r.svm, type="prob"))
library(ModTools)
head(predict(r.svm, type="prob"))
predict(r.rp, type="prob")
head(predict(r.rp, type="prob")
)
head(predict(r.svm, type="prob"))
mods <- list(rp=r.rp, rf=r.rf, svm=r.svm, c5=r.c5
, nn=r.nn, nb=r.nb, lda=r.lda, qda=r.qda, lb=r.lb)
lapply(mods, function(x) head(predict(x, type="prob")))
library(ModTools)
d.pim <- SplitTrainTest(d.pima, p = 0.2)
mdiab <- formula(diabetes ~ pregnant + glucose + pressure + triceps
+ insulin + mass + pedigree + age)
r.glm <- FitMod(mdiab, data=d.pim$train, fitfn="logit")
r.rp <- FitMod(mdiab, data=d.pim$train, fitfn="rpart")
r.rf <- FitMod(mdiab, data=d.pim$train, fitfn="randomForest")
r.svm <- FitMod(mdiab, data=d.pim$train, fitfn="svm")
r.c5 <- FitMod(mdiab, data=d.pim$train, fitfn="C5.0")
r.nn <- FitMod(mdiab, data=d.pim$train, fitfn="nnet")
r.nb <- FitMod(mdiab, data=d.pim$train, fitfn="naive_bayes")
r.lda <- FitMod(mdiab, data=d.pim$train, fitfn="lda")
r.qda <- FitMod(mdiab, data=d.pim$train, fitfn="qda")
r.lb <- FitMod(mdiab, data=d.pim$train, fitfn="lb")
mods <- list(glm=r.glm, rp=r.rp, rf=r.rf, svm=r.svm, c5=r.c5
, nn=r.nn, nb=r.nb, lda=r.lda, qda=r.qda, lb=r.lb)
sapply(mods, BrierScore)
head(predict(r.svm, type="prob"))
predict(r.rp, type="prob")
head(predict(r.svm, type="prob"))
head(predict(r.rp, type="prob"))
lapply(mods, function(x) head(predict(x, type="prob")))
library(ModTools)
lapply(mods, function(x) head(predict(x, type="prob")))
mods <- list(rp=r.rp, rf=r.rf, svm=r.svm, c5=r.c5
, nn=r.nn, nb=r.nb, lda=r.lda, qda=r.qda, lb=r.lb)
lapply(mods, function(x) head(predict(x, type="prob")))
sapply(mods, BrierScore)
library(ModTools)
d.pim <- SplitTrainTest(d.pima, p = 0.2)
mdiab <- formula(diabetes ~ pregnant + glucose + pressure + triceps
+ insulin + mass + pedigree + age)
r.glm <- FitMod(mdiab, data=d.pim$train, fitfn="logit")
r.rp <- FitMod(mdiab, data=d.pim$train, fitfn="rpart")
r.rf <- FitMod(mdiab, data=d.pim$train, fitfn="randomForest")
r.svm <- FitMod(mdiab, data=d.pim$train, fitfn="svm")
r.c5 <- FitMod(mdiab, data=d.pim$train, fitfn="C5.0")
r.nn <- FitMod(mdiab, data=d.pim$train, fitfn="nnet")
r.nb <- FitMod(mdiab, data=d.pim$train, fitfn="naive_bayes")
r.lda <- FitMod(mdiab, data=d.pim$train, fitfn="lda")
r.qda <- FitMod(mdiab, data=d.pim$train, fitfn="qda")
r.lb <- FitMod(mdiab, data=d.pim$train, fitfn="lb")
mods <- list(glm=r.glm, rp=r.rp, rf=r.rf, svm=r.svm, c5=r.c5
, nn=r.nn, nb=r.nb, lda=r.lda, qda=r.qda, lb=r.lb)
sapply(mods, BrierScore)
TModC(mods[c(1,2,3)])
TModC(mods)
debug(.predict.svm)
predict(r.svm, type="prob")
debug(ModTools:::.predict.svm)
predict(r.svm, type="prob")
attr(res)
str(res)
str(res)
str(res)
undebug(ModTools:::.predict.svm)
r.svm <- FitMod(mdiab, data=d.pim$train, fitfn="svm")
summary(r.svm)
tu <- Tune(r.svm,
kernel=c("radial", "sigmoid"),
cost=c(0.1,1,10,100,1000),
gamma=c(0.5,1,2,3,4), testset=d.pim$test)
Tune
ModTools:::Tune
ModTools:::Tune.default
tu <- Tune(r.svm,
kernel=c("radial", "sigmoid"),
cost=c(0.1,1,10,100,1000),
gamma=c(0.5,1,2,3,4), testset=d.pim$test)
library(ModTools)
r.svm
tu <- Tune(r.svm,
kernel=c("radial", "sigmoid"),
cost=c(0.1,1,10,100,1000),
gamma=c(0.5,1,2,3,4), testset=d.pim$test)
library(ModTools)
tu <- Tune(r.svm,
kernel=c("radial", "sigmoid"),
cost=c(0.1,1,10,100,1000),
gamma=c(0.5,1,2,3,4), testset=d.pim$test)
predict(r.svm, type="prob")
head(predict(r.svm, type="prob"))
head(predict(r.svm, type="class"))
library(ModTools)
head(predict(r.svm, type="prob"))
head(predict(r.svm, type="class"))
tu <- Tune(r.svm,
kernel=c("radial", "sigmoid"),
cost=c(0.1,1,10,100,1000),
gamma=c(0.5,1,2,3,4), testset=d.pim$test)
head(model.frame(r.glm))
r.glm <- FitMod(diabetes ~ ., data=d.pima, fitfn = "logit")
r.rp <- FitMod(diabetes ~ ., data=d.pima, fitfn = "rpart")
r.rf <- FitMod(diabetes ~ ., data=d.pima, fitfn = "randomForest")
example(TModC)
BrierScore(r.rp)
undebug(BrierScore)
class(r.rp)
methods(BrierScore)
predict(r.glm, type="response")
predict(r.rp, type="prob")
predict(r.rp, type="response")
undebug(predict)
predict.glm
rpart:::predict.rpart
ModelMetrics::brier(r.rp)
ModelMetrics::brier(r.glm)
BrierScore(r.rp)
BrierScore(r.rp)
BrierScore(r.glm)
ModelMetrics::brier(r.rp)
ModelMetrics::brier(r.glm)
BrierScore(r.glm)
BrierScore(r.rp)
BrierScore(r.rf)
ModelMetrics::brier(r.glm)
ModelMetrics::brier(r.rf)
BrierScore(r.glm)
BrierScore(r.rf)
DescToolsAddIns:::BuildModel()
library(ModTools)
DescToolsAddIns:::BuildModel()
r.logit <- FitMod(diabetes ~ ., data=d.pima, fitfn="logit")
summary(r.logit)
BrierScore(r.logit)
library(ModTools)
library(ModTools)
# get binomial model
r.logit <- FitMod(diabetes ~ ., data=d.pima, fitfn="logit")
# calculate Brier score with confidence intervals
BrierScore(r.logit)
BrierScoreCI(r.logit)
BrierScoreCI(r.logit, R=99)
library(ModTools)
# calculate Brier score with confidence intervals
BrierScore(r.logit)
BrierScoreCI(r.logit, R=99)
BrierScoreCI(r.logit, R=99)
warnings()
library(ModTools)
# calculate Brier score with confidence intervals
BrierScore(r.logit)
BrierScoreCI(r.logit, R=99)
library(ModTools)
library(pkgdown)
DescToolsAddIns:::FlipBackSlash()
build_home(pkg="C:/Users/andri/Documents/R/Projects/ModTools")
build_home(pkg="C:/Users/andri/Documents/R/Projects/ModTools")
build_site(pkg="C:/Users/andri/Documents/R/Projects/ModTools")
build_site(pkg="C:/Users/andri/Documents/R/Projects/ModTools")
install.packages("ModTools")
library(ModTools)
url <- "http://www.omegahat.net/R/bin/windows/contrib/4.2/RDCOMClient_0.96-1.zip"
install.packages(url, repos=NULL, type="binary")
library(ModTools)
d.pim <- SplitTrainTest(d.pima, p = 0.2)
mdiab <- formula(diabetes ~ pregnant + glucose + pressure + triceps
+                             + insulin + mass + pedigree + age)
r.glm <- FitMod(mdiab, data=d.pim$train, fitfn="logit")
r.rp <- FitMod(mdiab, data=d.pim$train, fitfn="rpart")
r.rf <- FitMod(mdiab, data=d.pim$train, fitfn="randomForest")
r.svm <- FitMod(mdiab, data=d.pim$train, fitfn="svm")
r.c5 <- FitMod(mdiab, data=d.pim$train, fitfn="C5.0")
r.nn <- FitMod(mdiab, data=d.pim$train, fitfn="nnet")
r.nb <- FitMod(mdiab, data=d.pim$train, fitfn="naive_bayes")
r.lda <- FitMod(mdiab, data=d.pim$train, fitfn="lda")
r.qda <- FitMod(mdiab, data=d.pim$train, fitfn="qda")
r.lb <- FitMod(mdiab, data=d.pim$train, fitfn="lb")
mods <- list(glm=r.glm, rp=r.rp, rf=r.rf, svm=r.svm, c5=r.c5
, nn=r.nn, nb=r.nb, lda=r.lda, qda=r.qda, lb=r.lb)
# insight in the Regression tree
plot(r.rp, box.palette = as.list(Pal("Helsana", alpha = 0.5)))
# Insample accuracy ...
TModC(mods, ord="auc")
# Insample accuracy ...
TModC(mods[1:5], ord="auc")
# Insample accuracy ...
TModC(mods[1:3], ord="auc")
# Insample accuracy ...
TModC(mods[1:2], ord="auc")
# Insample accuracy ...
TModC(mods[1:3], ord="auc")
# Insample accuracy ...
TModC(mods[3], ord="auc")
# Insample accuracy ...
TModC(mods[1], ord="auc")
# Insample accuracy ...
TModC(mods[2], ord="auc")
# Insample accuracy ...
TModC(mods[3], ord="auc")
# Insample accuracy ...
TModC(mods[-3], ord="auc")
# Insample accuracy ...
TModC(mods[c(1,2,4,5)], ord="auc")
# Insample accuracy ...
TModC(mods[c(1,2,4)], ord="auc")
# Insample accuracy ...
TModC(mods[c(1,2,5)], ord="auc")
# Insample accuracy ...
TModC(mods[c(1,2)], ord="auc")
# Insample accuracy ...
TModC(mods[c(1,2,6)], ord="auc")
# Insample accuracy ...
TModC(mods[c(1,2,7)], ord="auc")
# Insample accuracy ...
TModC(mods[c(2)], ord="auc")
# Insample accuracy ...
TModC(mods[c(3)], ord="auc")
debug(TModC)
# Insample accuracy ...
TModC(mods[c(3)], ord="auc")
undebug(TModC)
BrierScore(r.rf)
BrierScore
debug(BrierScore)
BrierScore(r.rf)
r.rf
summary(r.rf)
DescTools::Desc(r.rf)
BrierScore
r.rf
model.extract(r.rf, "response")
head(r.glm$model)
data_name = getCall(r.rf)$data
eval(data_name)
head(eval(data_name)
)
BrierScore
head(eval(data_name))
DescTools::Str(r.rf, max.level=1)
model.response(model.frame(r.rf))
model.frame(r.rf)
model.response(model.frame(r.rf))
BrierScore
r.rp$model
model.extract(r.rp$model, "response")
as.numeric(model.extract(r.rp$model, "response")) - 1
model.response(model.frame(r.rp))
as.numeric(model.response(model.frame(r.rp)) - 1
as.numeric(model.response(model.frame(r.rp))) - 1
as.numeric(model.extract(r.rp$model, "response")) - 1
as.numeric(model.response(model.frame(r.rp))) - 1
as.numeric(model.response(model.frame(r.glm))) - 1
as.numeric(model.response(model.frame(r.rp))) - 1
as.numeric(model.response(model.frame(r.rf))) - 1
as.numeric(model.response(model.frame(r.svm))) - 1
as.numeric(model.response(model.frame(r.c5))) - 1
model.frame(r.c5)
r.c5
as.numeric(model.response(model.frame(r.nn))) - 1
r.naive_bayes
r.nb
as.numeric(model.response(model.frame(r.nb))) - 1
as.numeric(model.response(model.frame(r.lda))) - 1
as.numeric(model.response(model.frame(r.qda))) - 1
as.numeric(model.response(model.frame(r.lb))) - 1
as.numeric(model.extract(r.c5$model, "response")) - 1
r.c5$model
data_name = getCall(r.c5)$data
eval(data_name)
model.extract(r.c5$model, "response")
ModTools::Response
model.response(model.frame(eval(x$call$formula)$terms))
model.response(model.frame(eval(r.rf$call$formula)$terms))
r.rf$call$formula
eval(r.rf$call$formula)
eval(r.rf$call$formula)$terms
x <- r.rf
x$terms <- eval(x$call$formula)
x$terms
model.response(model.frame(x))
resp <- function(x){
x$terms <- eval(x$call$formula)
model.response(model.frame(x))
}
resp(r.rp)
resp(r.glm)
resp(r.rf)
resp(r.svm)
resp(r.nn)
resp(r.lda)
resp(r.qda)
resp(r.c5)
resp(r.lb)
resp(r.c5)
resp(r.nb)
BrierScore
NumResponse <- function(x){
x$terms <- eval(x$call$formula)
as.numeric(model.response(model.frame(x))) - 1
}
NumResponse(r.glm)
NumResponse <- function(x){
x$terms <- eval(x$call$formula)
as.numeric(model.response(model.frame(x))) - 1
}
deps <- list(
A = c("B", "C", "D"),
B = c("C", "E"),
C = c("D", "F"),
D = c("C", "G"),
E = c("A"),
H = c("N")
)
get_all_deps <- function(item) {
todo <- unique(deps[[item]])
rval <- character()
while (length(todo) > 0) {
subitem <- todo[1]
todo <- todo[-1]
if (subitem != item) {  # don't add start item to the list
rval <- unique(c(rval, subitem))
to_add <- setdiff(deps[[subitem]], rval)
todo <- unique(c(todo, to_add))
}
}
return(sort(rval))
}
print(get_all_deps('A'))
print(get_all_deps('E'))
install.packages(c("AER", "broom", "car", "httr2", "memisc", "robustbase"))
library(DescTools)
set.seed(1)
x <- rt(100, df = 3)
y <- rt(100, df = 5)
HodgesLehmann(x)
#> [1] -0.04253799
HodgesLehmann(x, y)
# same as
wilcox.test(x, conf.int = TRUE)$estimate
x[1:5]
HodgesLehmann(x[1:5])
wilcox.test(x[1:5], conf.int = TRUE)$estimate
HodgesLehmann(x[1:50])
HodgesLehmann(x[1:50])
HodgesLehmann(x[1:90])
wilcox.test(x[1:90], conf.int = TRUE)$estimate
HodgesLehmann(x[1:80])
wilcox.test(x[1:80], conf.int = TRUE)$estimate
HodgesLehmann(x[1:70])
wilcox.test(x[1:70], conf.int = TRUE)$estimate
HodgesLehmann(x[1:60])
wilcox.test(x[1:60], conf.int = TRUE)$estimate
HodgesLehmann(x[1:50])
wilcox.test(x[1:50], conf.int = TRUE)$estimate
HodgesLehmann(x[1:49])
wilcox.test(x[1:49], conf.int = TRUE)$estimate
library(ModTools)
d.pim <- SplitTrainTest(d.pima, p = 0.2)
mdiab <- formula(diabetes ~ pregnant + glucose + pressure + triceps
+                             + insulin + mass + pedigree + age)
r.glm <- FitMod(mdiab, data=d.pim$train, fitfn="logit")
r.rp <- FitMod(mdiab, data=d.pim$train, fitfn="rpart")
r.rf <- FitMod(mdiab, data=d.pim$train, fitfn="randomForest")
r.svm <- FitMod(mdiab, data=d.pim$train, fitfn="svm")
r.c5 <- FitMod(mdiab, data=d.pim$train, fitfn="C5.0")
r.nn <- FitMod(mdiab, data=d.pim$train, fitfn="nnet")
r.nb <- FitMod(mdiab, data=d.pim$train, fitfn="naive_bayes")
r.nn <- FitMod(mdiab, data=d.pim$train, fitfn="nnet")
r.nb <- FitMod(mdiab, data=d.pim$train, fitfn="naive_bayes")
r.lda <- FitMod(mdiab, data=d.pim$train, fitfn="lda")
r.qda <- FitMod(mdiab, data=d.pim$train, fitfn="qda")
r.lb <- FitMod(mdiab, data=d.pim$train, fitfn="lb")
mods <- list(glm=r.glm, rp=r.rp, rf=r.rf, svm=r.svm, c5=r.c5
, nn=r.nn, nb=r.nb, lda=r.lda, qda=r.qda, lb=r.lb)
# insight in the Regression tree
plot(r.rp, box.palette = as.list(Pal("Helsana", alpha = 0.5)))
# Insample accuracy ...
TModC(mods[c(3)], ord="auc")
BrierScore(r.rf)
model.extract(r.glm$model, "response")
data_name = getCall(r.rf)$data
eval(data_name)
model.response(model.frame(r.rf))
as.numeric(model.extract(r.rp$model, "response")) - 1
as.numeric(model.response(model.frame(r.rp))) - 1
as.numeric(model.response(model.frame(r.glm))) - 1
as.numeric(model.response(model.frame(r.rf))) - 1
as.numeric(model.response(model.frame(r.svm))) - 1
as.numeric(model.response(model.frame(r.nn))) - 1
as.numeric(model.response(model.frame(r.lda))) - 1
as.numeric(model.response(model.frame(r.qda))) - 1
as.numeric(model.response(model.frame(r.lb))) - 1
as.numeric(model.response(model.frame(r.c5))) - 1
as.numeric(model.response(model.frame(r.nb))) - 1
as.numeric(model.extract(r.c5$model, "response")) - 1
data_name = getCall(r.c5)$data
eval(data_name)
r.c5$re
ModTools::Response
x <- r.rf
NumResponse <- function(x){
x$terms <- eval(x$call$formula)
as.numeric(model.response(model.frame(x))) - 1
}
NumResponse(r.glm)
resp(r.rp)
resp(r.rf)
resp(r.svm)
resp(r.nn)
resp(r.lda)
resp(r.qda)
resp(r.lb)
resp(r.c5)
resp(r.nb)
model.extract(r.glm$model, "response")
DescTools::Desc(model.extract(r.glm$model, "response"))
